{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing dataset length:  6400\n",
      "Validate dataset length:  1600\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "# Training data set has 80000 lines of data\n",
    "# Load train data and split into two new sets: \n",
    "#      another train data set with front 80% = 6400 lines of data\n",
    "#      validate data set with back 20% = 1600 lines of data\n",
    "\n",
    "train_data = np.loadtxt(\"./training/dataset_training.txt\", delimiter = \",\")\n",
    "\n",
    "train=[]\n",
    "validate=[]\n",
    "# get new train data set with 6400 lines\n",
    "for i in range(0, 6400):\n",
    "    train.append(train_data[i])\n",
    "print(\"Traing dataset length: \", len(train))\n",
    "\n",
    "# get validate data set with 1600 lines\n",
    "for i in range(6400, 8000):\n",
    "    validate.append(train_data[i])\n",
    "print(\"Validate dataset length: \", len(validate))\n",
    "\n",
    "# transfer into numpy array\n",
    "train=np.array(train)\n",
    "validate=np.array(validate)\n",
    "\n",
    "# split train and validate data set with targert and features sets\n",
    "train_t = train[:, -1]\n",
    "train_f = train[:, :-1]\n",
    "\n",
    "validate_t = validate[:, -1]\n",
    "validate_f = validate[:, :-1]\n",
    "\n",
    "# Normalize feature attributes [0,1]\n",
    "# normalize train set on each non-zero feature with \"max\" if axis=0\n",
    "train_f_n = preprocessing.normalize(train[:, :-1], norm='max', axis=0)\n",
    "\n",
    "# normalize test set on each non-zero feature with \"max\" if axis=0\n",
    "validate_f_n = preprocessing.normalize(validate[:, :-1], norm='max', axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After normalization:\n",
      "Accuracy on training dataset: 0.913125\n",
      "F1-score on training dataset: 0.8738656987295825\n",
      "---------------\n",
      "Accuracy on validate dataset: 0.86625\n",
      "F1-score on validate  dataset: 0.7834008097165992\n"
     ]
    }
   ],
   "source": [
    "# Using Default arguments in KNN classifer and see the accuracy in tranning / validate dataset\n",
    "\n",
    "# Train the model with the training sets\n",
    "knn_default = KNeighborsClassifier()\n",
    "knn_default.fit(train_f_n, train_t)\n",
    "\n",
    "# Predict the response for train dataset\n",
    "pred_train_t = knn_default.predict(train_f_n)\n",
    "\n",
    "# Predict the response for validate dataset\n",
    "pred_validate_t = knn_default.predict(validate_f_n)\n",
    "\n",
    "print(\"After normalization:\")\n",
    "print(\"Accuracy on training dataset:\",metrics.accuracy_score(train_t, pred_train_t))\n",
    "print(\"F1-score on training dataset:\", f1_score(train_t, pred_train_t))\n",
    "\n",
    "print(\"---------------\")\n",
    "\n",
    "\n",
    "print(\"Accuracy on validate dataset:\",metrics.accuracy_score(validate_t, pred_validate_t))\n",
    "print(\"F1-score on validate  dataset:\", f1_score(validate_t, pred_validate_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0 num_of_neighbours= 3 p= 1 weights= uniform Accuracy on train dataset: 0.92515625 Accuracy on validate dataset: 0.8475\n",
      "index: 1 num_of_neighbours= 3 p= 1 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.8475\n",
      "index: 2 num_of_neighbours= 3 p= 2 weights= uniform Accuracy on train dataset: 0.92890625 Accuracy on validate dataset: 0.856875\n",
      "index: 3 num_of_neighbours= 3 p= 2 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.856875\n",
      "index: 4 num_of_neighbours= 3 p= 3 weights= uniform Accuracy on train dataset: 0.93 Accuracy on validate dataset: 0.855625\n",
      "index: 5 num_of_neighbours= 3 p= 3 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.855625\n",
      "index: 6 num_of_neighbours= 4 p= 1 weights= uniform Accuracy on train dataset: 0.8909375 Accuracy on validate dataset: 0.84125\n",
      "index: 7 num_of_neighbours= 4 p= 1 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.850625\n",
      "index: 8 num_of_neighbours= 4 p= 2 weights= uniform Accuracy on train dataset: 0.89046875 Accuracy on validate dataset: 0.83875\n",
      "index: 9 num_of_neighbours= 4 p= 2 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.86\n",
      "index: 10 num_of_neighbours= 4 p= 3 weights= uniform Accuracy on train dataset: 0.8865625 Accuracy on validate dataset: 0.835625\n",
      "index: 11 num_of_neighbours= 4 p= 3 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.85875\n",
      "index: 12 num_of_neighbours= 5 p= 1 weights= uniform Accuracy on train dataset: 0.91609375 Accuracy on validate dataset: 0.865625\n",
      "index: 13 num_of_neighbours= 5 p= 1 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.865625\n",
      "index: 14 num_of_neighbours= 5 p= 2 weights= uniform Accuracy on train dataset: 0.913125 Accuracy on validate dataset: 0.86625\n",
      "index: 15 num_of_neighbours= 5 p= 2 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.86625\n",
      "index: 16 num_of_neighbours= 5 p= 3 weights= uniform Accuracy on train dataset: 0.9075 Accuracy on validate dataset: 0.86\n",
      "index: 17 num_of_neighbours= 5 p= 3 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.860625\n",
      "index: 18 num_of_neighbours= 6 p= 1 weights= uniform Accuracy on train dataset: 0.8915625 Accuracy on validate dataset: 0.85\n",
      "index: 19 num_of_neighbours= 6 p= 1 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.8675\n",
      "index: 20 num_of_neighbours= 6 p= 2 weights= uniform Accuracy on train dataset: 0.8915625 Accuracy on validate dataset: 0.85\n",
      "index: 21 num_of_neighbours= 6 p= 2 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.87125\n",
      "index: 22 num_of_neighbours= 6 p= 3 weights= uniform Accuracy on train dataset: 0.88453125 Accuracy on validate dataset: 0.850625\n",
      "index: 23 num_of_neighbours= 6 p= 3 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.863125\n",
      "index: 24 num_of_neighbours= 7 p= 1 weights= uniform Accuracy on train dataset: 0.91078125 Accuracy on validate dataset: 0.879375\n",
      "index: 25 num_of_neighbours= 7 p= 1 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.879375\n",
      "index: 26 num_of_neighbours= 7 p= 2 weights= uniform Accuracy on train dataset: 0.90796875 Accuracy on validate dataset: 0.8675\n",
      "index: 27 num_of_neighbours= 7 p= 2 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.868125\n",
      "index: 28 num_of_neighbours= 7 p= 3 weights= uniform Accuracy on train dataset: 0.90640625 Accuracy on validate dataset: 0.861875\n",
      "index: 29 num_of_neighbours= 7 p= 3 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.8625\n",
      "index: 30 num_of_neighbours= 8 p= 1 weights= uniform Accuracy on train dataset: 0.8921875 Accuracy on validate dataset: 0.848125\n",
      "index: 31 num_of_neighbours= 8 p= 1 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.873125\n",
      "index: 32 num_of_neighbours= 8 p= 2 weights= uniform Accuracy on train dataset: 0.890625 Accuracy on validate dataset: 0.8525\n",
      "index: 33 num_of_neighbours= 8 p= 2 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.87125\n",
      "index: 34 num_of_neighbours= 8 p= 3 weights= uniform Accuracy on train dataset: 0.88578125 Accuracy on validate dataset: 0.850625\n",
      "index: 35 num_of_neighbours= 8 p= 3 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.865\n",
      "index: 36 num_of_neighbours= 9 p= 1 weights= uniform Accuracy on train dataset: 0.9084375 Accuracy on validate dataset: 0.865\n",
      "index: 37 num_of_neighbours= 9 p= 1 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.865\n",
      "index: 38 num_of_neighbours= 9 p= 2 weights= uniform Accuracy on train dataset: 0.90578125 Accuracy on validate dataset: 0.87\n",
      "index: 39 num_of_neighbours= 9 p= 2 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.870625\n",
      "index: 40 num_of_neighbours= 9 p= 3 weights= uniform Accuracy on train dataset: 0.90265625 Accuracy on validate dataset: 0.86125\n",
      "index: 41 num_of_neighbours= 9 p= 3 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.861875\n",
      "index: 42 num_of_neighbours= 10 p= 1 weights= uniform Accuracy on train dataset: 0.89140625 Accuracy on validate dataset: 0.85625\n",
      "index: 43 num_of_neighbours= 10 p= 1 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.878125\n",
      "index: 44 num_of_neighbours= 10 p= 2 weights= uniform Accuracy on train dataset: 0.889375 Accuracy on validate dataset: 0.853125\n",
      "index: 45 num_of_neighbours= 10 p= 2 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.8775\n",
      "index: 46 num_of_neighbours= 10 p= 3 weights= uniform Accuracy on train dataset: 0.885 Accuracy on validate dataset: 0.840625\n",
      "index: 47 num_of_neighbours= 10 p= 3 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.86625\n",
      "index: 48 num_of_neighbours= 11 p= 1 weights= uniform Accuracy on train dataset: 0.905 Accuracy on validate dataset: 0.87375\n",
      "index: 49 num_of_neighbours= 11 p= 1 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.873125\n",
      "index: 50 num_of_neighbours= 11 p= 2 weights= uniform Accuracy on train dataset: 0.90265625 Accuracy on validate dataset: 0.87\n",
      "index: 51 num_of_neighbours= 11 p= 2 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.87125\n",
      "index: 52 num_of_neighbours= 11 p= 3 weights= uniform Accuracy on train dataset: 0.89453125 Accuracy on validate dataset: 0.863125\n",
      "index: 53 num_of_neighbours= 11 p= 3 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.86375\n",
      "index: 54 num_of_neighbours= 12 p= 1 weights= uniform Accuracy on train dataset: 0.89125 Accuracy on validate dataset: 0.863125\n",
      "index: 55 num_of_neighbours= 12 p= 1 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.880625\n",
      "index: 56 num_of_neighbours= 12 p= 2 weights= uniform Accuracy on train dataset: 0.8871875 Accuracy on validate dataset: 0.85625\n",
      "index: 57 num_of_neighbours= 12 p= 2 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.875\n",
      "index: 58 num_of_neighbours= 12 p= 3 weights= uniform Accuracy on train dataset: 0.8821875 Accuracy on validate dataset: 0.8475\n",
      "index: 59 num_of_neighbours= 12 p= 3 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.866875\n",
      "index: 60 num_of_neighbours= 13 p= 1 weights= uniform Accuracy on train dataset: 0.9034375 Accuracy on validate dataset: 0.875625\n",
      "index: 61 num_of_neighbours= 13 p= 1 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.875\n",
      "index: 62 num_of_neighbours= 13 p= 2 weights= uniform Accuracy on train dataset: 0.901875 Accuracy on validate dataset: 0.86875\n",
      "index: 63 num_of_neighbours= 13 p= 2 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.869375\n",
      "index: 64 num_of_neighbours= 13 p= 3 weights= uniform Accuracy on train dataset: 0.8934375 Accuracy on validate dataset: 0.868125\n",
      "index: 65 num_of_neighbours= 13 p= 3 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.86875\n",
      "index: 66 num_of_neighbours= 14 p= 1 weights= uniform Accuracy on train dataset: 0.8884375 Accuracy on validate dataset: 0.868125\n",
      "index: 67 num_of_neighbours= 14 p= 1 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.881875\n",
      "index: 68 num_of_neighbours= 14 p= 2 weights= uniform Accuracy on train dataset: 0.886875 Accuracy on validate dataset: 0.85875\n",
      "index: 69 num_of_neighbours= 14 p= 2 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.875\n",
      "index: 70 num_of_neighbours= 14 p= 3 weights= uniform Accuracy on train dataset: 0.880625 Accuracy on validate dataset: 0.85375\n",
      "index: 71 num_of_neighbours= 14 p= 3 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.873125\n",
      "index: 72 num_of_neighbours= 15 p= 1 weights= uniform Accuracy on train dataset: 0.90078125 Accuracy on validate dataset: 0.878125\n",
      "index: 73 num_of_neighbours= 15 p= 1 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.878125\n",
      "index: 74 num_of_neighbours= 15 p= 2 weights= uniform Accuracy on train dataset: 0.89828125 Accuracy on validate dataset: 0.87\n",
      "index: 75 num_of_neighbours= 15 p= 2 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.870625\n",
      "index: 76 num_of_neighbours= 15 p= 3 weights= uniform Accuracy on train dataset: 0.895 Accuracy on validate dataset: 0.870625\n",
      "index: 77 num_of_neighbours= 15 p= 3 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.87125\n",
      "index: 78 num_of_neighbours= 16 p= 1 weights= uniform Accuracy on train dataset: 0.8875 Accuracy on validate dataset: 0.86625\n",
      "index: 79 num_of_neighbours= 16 p= 1 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.884375\n",
      "index: 80 num_of_neighbours= 16 p= 2 weights= uniform Accuracy on train dataset: 0.88703125 Accuracy on validate dataset: 0.860625\n",
      "index: 81 num_of_neighbours= 16 p= 2 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.873125\n",
      "index: 82 num_of_neighbours= 16 p= 3 weights= uniform Accuracy on train dataset: 0.8796875 Accuracy on validate dataset: 0.8575\n",
      "index: 83 num_of_neighbours= 16 p= 3 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.874375\n",
      "index: 84 num_of_neighbours= 17 p= 1 weights= uniform Accuracy on train dataset: 0.90078125 Accuracy on validate dataset: 0.876875\n",
      "index: 85 num_of_neighbours= 17 p= 1 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.8775\n",
      "index: 86 num_of_neighbours= 17 p= 2 weights= uniform Accuracy on train dataset: 0.89828125 Accuracy on validate dataset: 0.870625\n",
      "index: 87 num_of_neighbours= 17 p= 2 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.87125\n",
      "index: 88 num_of_neighbours= 17 p= 3 weights= uniform Accuracy on train dataset: 0.88921875 Accuracy on validate dataset: 0.87375\n",
      "index: 89 num_of_neighbours= 17 p= 3 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.87625\n",
      "index: 90 num_of_neighbours= 18 p= 1 weights= uniform Accuracy on train dataset: 0.88875 Accuracy on validate dataset: 0.8675\n",
      "index: 91 num_of_neighbours= 18 p= 1 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.881875\n",
      "index: 92 num_of_neighbours= 18 p= 2 weights= uniform Accuracy on train dataset: 0.885 Accuracy on validate dataset: 0.8625\n",
      "index: 93 num_of_neighbours= 18 p= 2 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.874375\n",
      "index: 94 num_of_neighbours= 18 p= 3 weights= uniform Accuracy on train dataset: 0.8784375 Accuracy on validate dataset: 0.860625\n",
      "index: 95 num_of_neighbours= 18 p= 3 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.878125\n",
      "index: 96 num_of_neighbours= 19 p= 1 weights= uniform Accuracy on train dataset: 0.89828125 Accuracy on validate dataset: 0.87625\n",
      "index: 97 num_of_neighbours= 19 p= 1 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.87875\n",
      "index: 98 num_of_neighbours= 19 p= 2 weights= uniform Accuracy on train dataset: 0.8946875 Accuracy on validate dataset: 0.873125\n",
      "index: 99 num_of_neighbours= 19 p= 2 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.875\n",
      "index: 100 num_of_neighbours= 19 p= 3 weights= uniform Accuracy on train dataset: 0.88953125 Accuracy on validate dataset: 0.87375\n",
      "index: 101 num_of_neighbours= 19 p= 3 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.875\n",
      "index: 102 num_of_neighbours= 20 p= 1 weights= uniform Accuracy on train dataset: 0.886875 Accuracy on validate dataset: 0.8625\n",
      "index: 103 num_of_neighbours= 20 p= 1 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.88\n",
      "index: 104 num_of_neighbours= 20 p= 2 weights= uniform Accuracy on train dataset: 0.88109375 Accuracy on validate dataset: 0.863125\n",
      "index: 105 num_of_neighbours= 20 p= 2 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.875625\n",
      "index: 106 num_of_neighbours= 20 p= 3 weights= uniform Accuracy on train dataset: 0.8753125 Accuracy on validate dataset: 0.861875\n",
      "index: 107 num_of_neighbours= 20 p= 3 weights= distance Accuracy on train dataset: 1.0 Accuracy on validate dataset: 0.874375\n",
      "Best parameters: 16 1 distance\n",
      "MAX accuracy:  79 0.884375\n"
     ]
    }
   ],
   "source": [
    "# Tunning the parameters in KNN to get a better accuracy\n",
    "\n",
    "num_of_neighbours = range(3, 21)\n",
    "p=[1, 2, 3]\n",
    "weight_array=['uniform', 'distance']\n",
    "\n",
    "validate_accuracy = []\n",
    "# use iteration to caclulator different k in models, then return the average accuracy \n",
    "sum_array = []\n",
    "index=0\n",
    "max_index=0\n",
    "max_accuracy=0\n",
    "max_n=0\n",
    "max_i=0\n",
    "max_j='uniform'\n",
    "for n in num_of_neighbours:\n",
    "    for i in p:\n",
    "        for j in weight_array:\n",
    "            knn_test= KNeighborsClassifier(n_neighbors=n, p=i, weights=j)\n",
    "            knn_test.fit(train_f_n, train_t)\n",
    "            pred_validate_t = knn_test.predict(validate_f_n)\n",
    "            pred_train_t = knn_test.predict(train_f_n)\n",
    "            \n",
    "            t_accuracy =metrics.accuracy_score(train_t, pred_train_t)\n",
    "            v_accuracy =metrics.accuracy_score(validate_t, pred_validate_t)\n",
    "            validate_accuracy.append(v_accuracy)\n",
    "            print(\"index:\", index,\"num_of_neighbours=\", n,\"p=\", i, \"weights=\", j, \"Accuracy on train dataset:\", t_accuracy, \"Accuracy on validate dataset:\", v_accuracy)\n",
    "            sum_array.append((index, n, i, j, metrics.accuracy_score(validate_t, pred_validate_t)))\n",
    "            if v_accuracy > max_accuracy:\n",
    "                max_accuracy=v_accuracy\n",
    "                max_index=index\n",
    "                max_n=n\n",
    "                max_i=i\n",
    "                max_j=j\n",
    "            index=index+1\n",
    "print(\"Best parameters:\", max_n, max_i, max_j)\n",
    "print(\"MAX accuracy: \", max_index, max_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After normalization:\n",
      "Accuracy on training dataset: 1.0\n",
      "F1-score on training dataset: 1.0\n",
      "---------------\n",
      "Accuracy on validate dataset: 0.884375\n",
      "F1-score on validate dataset: 0.8070907194994786\n"
     ]
    }
   ],
   "source": [
    "# test the knn with best parameters:\n",
    "knn_2 = KNeighborsClassifier(n_neighbors=16, p=1, weights='distance')\n",
    "# Train the model with the training sets\n",
    "knn_2.fit(train_f_n, train_t)\n",
    "\n",
    "# Predict the response for train dataset\n",
    "pred_train_t = knn_2.predict(train_f_n)\n",
    "print(\"After normalization:\")\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy on training dataset:\",metrics.accuracy_score(train_t, pred_train_t))\n",
    "print(\"F1-score on training dataset:\", f1_score(train_t, pred_train_t))\n",
    "print(\"---------------\")\n",
    "\n",
    "# Predict the response for validate dataset\n",
    "pred_validate_t = knn_2.predict(validate_f_n)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy on validate dataset:\",metrics.accuracy_score(validate_t, pred_validate_t))\n",
    "print(\"F1-score on validate dataset:\", f1_score(validate_t, pred_validate_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data set - cross validation:\n",
      "acccuracy on model 1: 0.987656\n",
      "acccuracy on model 2: 0.989844\n",
      "acccuracy on model 3: 0.988125\n",
      "acccuracy on model 4: 0.988594\n",
      "acccuracy on model 5: 0.987812\n",
      "acccuracy on model 6: 0.986719\n",
      "acccuracy on model 7: 0.985625\n",
      "acccuracy on model 8: 0.988750\n",
      "acccuracy on model 9: 0.986250\n",
      "acccuracy on model 10: 0.987656\n",
      "Average Accuracy: 0.987703 \n",
      "-----------------------\n",
      "Validate data set - cross validation:\n",
      "acccuracy on model 1: 0.876250\n",
      "acccuracy on model 2: 0.877500\n",
      "acccuracy on model 3: 0.878125\n",
      "acccuracy on model 4: 0.873125\n",
      "acccuracy on model 5: 0.876250\n",
      "acccuracy on model 6: 0.878125\n",
      "acccuracy on model 7: 0.883750\n",
      "acccuracy on model 8: 0.878750\n",
      "acccuracy on model 9: 0.880000\n",
      "acccuracy on model 10: 0.878125\n",
      "Average Accuracy: 0.878000\n",
      "-------------------------------\n",
      "Final Evaluation on training data set:\n",
      "Accuracy: 0.98671875\n",
      "tn fp fn tp\n",
      "4056 17 68 2259\n",
      "F1-SCORE = 0.981534\n",
      "--------------------\n",
      "Final Evaluation on validate data set:\n",
      "Accuracy: 0.878125\n",
      "tn fp fn tp\n",
      "1025 35 160 380\n",
      "F1-SCORE = 0.795812\n"
     ]
    }
   ],
   "source": [
    "#### cross validation  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create a new KNN model for best performance paramter obtained previously\n",
    "knn_cv = KNeighborsClassifier(n_neighbors=16, weights='distance', p=1)\n",
    "\n",
    "# Train model with cross-validation of 10 \n",
    "n = 10\n",
    "cv_result = cross_validate(knn_cv, train_f_n, train_t, cv=n, return_estimator=True)\n",
    "estimator = cv_result['estimator']\n",
    "\n",
    "print(\"Training data set - cross validation:\")\n",
    "accuracy_scores = []\n",
    "for i in range(n):\n",
    "    pred_train_cv = estimator[i].predict(train_f_n)\n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "    accuracy_score = metrics.accuracy_score(train_t, pred_train_cv)\n",
    "    accuracy_scores.append(accuracy_score)\n",
    "    print(\"acccuracy on model %d: %f\" % (i+1,accuracy_score))\n",
    "accuracy_scores = np.array(accuracy_scores)\n",
    "print(\"Average Accuracy: %f \" % (accuracy_scores.mean()))\n",
    "print(\"-----------------------\")\n",
    "print(\"Validate data set - cross validation:\")\n",
    "maxscore = -1\n",
    "best_result_test = []\n",
    "accuracy_scores = []\n",
    "model = -1\n",
    "for i in range(n):\n",
    "    pred_validate_cv = estimator[i].predict(validate_f_n)\n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "    accuracy_score = metrics.accuracy_score(validate_t, pred_validate_cv)\n",
    "    if accuracy_score > maxscore:\n",
    "        maxscore = accuracy_score\n",
    "        best_result = pred_validate_cv\n",
    "        model = i\n",
    "    accuracy_scores.append(accuracy_score)\n",
    "    print(\"acccuracy on model %d: %f\" % (i+1,accuracy_score))\n",
    "accuracy_scores = np.array(accuracy_scores)\n",
    "print(\"Average Accuracy: %f\" % (accuracy_scores.mean()))\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "pred_train_cv = estimator[model-1].predict(train_f_n)\n",
    "pred_validate_cv = estimator[model-1].predict(validate_f_n)\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Final Evaluation on training data set:\")\n",
    "print(\"Accuracy:\",metrics.accuracy_score(train_t, pred_train_cv))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(train_t, pred_train_cv).ravel()\n",
    "print(\"tn\", \"fp\", \"fn\", \"tp\")\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "print('F1-SCORE = %f' %(f1_score(train_t, pred_train_cv)))\n",
    "print(\"--------------------\")\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Final Evaluation on validate data set:\")\n",
    "print(\"Accuracy:\",metrics.accuracy_score(validate_t, pred_validate_cv))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(validate_t, pred_validate_cv).ravel()\n",
    "print(\"tn\", \"fp\", \"fn\", \"tp\")\n",
    "print(tn, fp, fn, tp)\n",
    "print('F1-SCORE = %f' %(f1_score(validate_t, pred_validate_cv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data2 = np.loadtxt(\"./testing/dataset_testing.txt\", delimiter = \",\")\n",
    "test_t2 = test_data2[:, -1]\n",
    "test_x2 = test_data2[:, :-1]\n",
    "\n",
    "test_x2 = preprocessing.normalize(test_data2[:, :-1], norm='max', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Evaluation on testing data set:\n",
      "Accuracy: 0.861\n",
      "tn fp fn tp\n",
      "1198 49 229 524\n",
      "F1-SCORE = 0.790347\n"
     ]
    }
   ],
   "source": [
    "pred_test_cv = estimator[model-1].predict(test_x2)\n",
    "\n",
    "print(\"Final Evaluation on testing data set:\")\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_t2, pred_test_cv))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(test_t2, pred_test_cv).ravel()\n",
    "print(\"tn\", \"fp\", \"fn\", \"tp\")\n",
    "print(tn, fp, fn, tp)\n",
    "print('F1-SCORE = %f' %(f1_score(test_t2, pred_test_cv)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## update predictor_2_y.txt\n",
    "a_file = open(\"predictor_2_y.txt\", \"w\")\n",
    "for row in pred_test_cv:\n",
    "    a_file.write(str(row))\n",
    "    a_file.write(\"\\n\")\n",
    "\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
